<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  

  
  

  
  
  
  
  

  <title>SpanBERT</title>
  <meta name="title" content="SpanBERT">
  <meta name="description" content="SpanBERT is a model created by Facebook AI and Allen Institute in
January 2019 and published in this paper “SpanBERT: Improving
Pre-training by Representing and Predicting
Spans”. SpanBERT is just an
extension to BERT where it better represents and predict continuous
random spans of text, rather than random tokens. This is crucial since
many NLP tasks involve spans of text rather than single tokens. SpanBERT
is different from BERT in both the masking scheme and the training
objectives:

">
  <meta name="author" content="Phanxuan Phuc">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- Google / Search Engine Tags -->
  <meta itemprop="name" content="SpanBERT">
  <meta itemprop="description" content="SpanBERT is a model created by Facebook AI and Allen Institute in
January 2019 and published in this paper “SpanBERT: Improving
Pre-training by Representing and Predicting
Spans”. SpanBERT is just an
extension to BERT where it better represents and predict continuous
random spans of text, rather than random tokens. This is crucial since
many NLP tasks involve spans of text rather than single tokens. SpanBERT
is different from BERT in both the masking scheme and the training
objectives:

">
  <meta itemprop="image" content="/language-modeling/media/SpanBERT/image0.png">

  <!-- OpenGraph Meta Tags -->
  <meta property="og:url" content="http://localhost:4000">
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Phuc Phan's Blog"/>
  <meta property="og:title" content="SpanBERT">
  <meta property="og:description" content="SpanBERT is a model created by Facebook AI and Allen Institute in
January 2019 and published in this paper “SpanBERT: Improving
Pre-training by Representing and Predicting
Spans”. SpanBERT is just an
extension to BERT where it better represents and predict continuous
random spans of text, rather than random tokens. This is crucial since
many NLP tasks involve spans of text rather than single tokens. SpanBERT
is different from BERT in both the masking scheme and the training
objectives:

">
  <meta property="og:image" content="/language-modeling/media/SpanBERT/image0.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="SpanBERT">
  <meta name="twitter:description" content="SpanBERT is a model created by Facebook AI and Allen Institute in
January 2019 and published in this paper “SpanBERT: Improving
Pre-training by Representing and Predicting
Spans”. SpanBERT is just an
extension to BERT where it better represents and predict continuous
random spans of text, rather than random tokens. This is crucial since
many NLP tasks involve spans of text rather than single tokens. SpanBERT
is different from BERT in both the masking scheme and the training
objectives:

">
  
  <meta name="twitter:image" content="/language-modeling/media/SpanBERT/image0.png">

  <link rel="apple-touch-icon" sizes="57x57" href="/images/favicons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/favicons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/favicons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/images/favicons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/favicons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/images/favicons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-194x194.png" sizes="194x194">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-512x512.png" sizes="512x512">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="shortcut icon" href="/images/favicons/favicon.ico">
  <meta name="msapplication-TileColor" content="#ffc40d">
  <meta name="msapplication-TileImage" content="/images/favicons/mstile-144x144.png">
  <meta name="msapplication-square70x70logo" content="/images/favicons/mstile-70x70.png" />
  <meta name="msapplication-square150x150logo" content="/images/favicons/mstile-150x150.png" />
  <meta name="msapplication-wide310x150logo" content="/images/favicons/mstile-310x150.png" />
  <meta name="msapplication-square310x310logo" content="/images/favicons/mstile-310x310.png" />
  <meta name="theme-color" content="#ffffff">
  
  <link rel="stylesheet" href="/css/main.css?1680763441293376118">
  <link rel="canonical" href="http://localhost:4000/language-modeling/SpanBERT">
  <link rel="alternate" type="application/rss+xml" title="Phuc Phan's Blog" href="/feed.xml">
  <script type="text/javascript" src="/js/jquery.v3.3.1.min.js"></script>
  <!-- <script type="text/javascript" src="/js/simple-jekyll-search.min.js"></script> -->
  <script type="text/javascript" src="/js/simple-blog-search.min.js"></script>
</head>

  <body>
    <span class="mobile btn-mobile-menu">
  <i class="extra-big-icon iconify-inline icon-list btn-mobile-menu__icon" data-icon="gg:menu-round"></i>
  <i class="extra-big-icon iconify-inline icon-x-circle btn-mobile-close__icon hidden" data-icon="ion:close-circle-outline"></i>
</span>

<header class="panel-cover "
  style="background-image: url(/images/forest.jpg)">
  <div class="panel-main panel-cover--overlay">

    <div class="panel-main__inner panel-inverted">
      <div class="panel-main__content">
        <img src="/images/avatar.jpg" class="user-image"
        onmouseover="this.src='/images/avatar-light.jpg';"
        onmouseout="this.src='/images/avatar.jpg';">
        <h1 class="panel-cover__title panel-title">
          <a href="/">Phanxuan Phuc</a>
        </h1>
        </a>
        <h6 class="panel-cover__title panel-subtitle">fakerphan
          <i class="medium-icon iconify-inline" data-icon="foundation:male-symbol"></i>
        </h6>
        <nav class="cover-navigation navigation--social">
    <ul class="navigation">

      
      <!-- Email -->
      <li class="navigation__item">
        <a href="mailto:phanxuanphucnd@gmail.com" target="_blank" title="Email">
          <i class="big-icon iconify-inline" data-icon="fluent:mail-copy-24-filled"></i>
        </a>
      </li>
      

      
      <!-- LinkedIn -->
      <li class="navigation__item">
        <a href="https://www.linkedin.com/in/phanxuanphucnd" target="_blank" title="LinkedIn">
          <i class="big-icon iconify-inline" data-icon="akar-icons:linkedin-fill"></i>
        </a>
      </li>
      

      
      <!-- GitHub -->
      <li class="navigation__item">
        <a href="https://www.github.com/phanxuanphucnd" target="_blank" title="GitHub">
          <i class="big-icon iconify-inline" data-icon="akar-icons:github-fill"></i>
        </a>
      </li>
      

      <li class="navigation__item">
        <a href="https://scholar.google.com/citations?user=ipcDPCQAAAAJ&hl=vi" title="Google Scholar" target="_blank">
          <i class="big-icon iconify-inline" data-icon="mdi:google"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>

      <li class="navigation__item">
        <a href="https://www.facebook.com/phanxuanphucnd" title="Facebook" target="_blank">
          <i class="big-icon iconify-inline" data-icon="ic:outline-facebook"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>
    </ul>
  </nav>
        
        <form class="search-container" onsubmit="return searchTheArchives()" >
          <input type="search" id="search-input" placeholder="Search.." autocomplete="off" style="padding-right: 40px;">
        </form>

        <hr class="panel-cover__divider panel-cover__divider--secondary">
        
        <div class="navigation-wrapper">
          <p class="panel-cover__description">I’m a AI Engineer in Vin Bigdata. And I summarize research papers in these topics:</p>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              
              
              <li class="navigation__item">
                <a href="/cross-lingual-lm" class="blog-button" id="cross-lingual-lm"
                onclick="activateButton(this.id)">Cross-lingual Langluage Model</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/language-modeling" class="blog-button" id="language-modeling"
                onclick="activateButton(this.id)">Language Modeling</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/machine-translation" class="blog-button" id="machine-translation"
                onclick="activateButton(this.id)">Machine Translation</a>
              </li>
              
              
              
              
              
              <li class="navigation__item">
                <a href="/multilingual-nmt" class="blog-button" id="multilingual-nmt"
                onclick="activateButton(this.id)">Multilingual NMT</a>
              </li>
              
              
              
              
              
              
            </ul>
          </nav>
        </div>
        
        <hr class="panel-cover__divider">
      </div>

    </div>

    <!-- <div class="panel-cover--overlay"></div> -->
  </div>
</header>

    <div class="content-wrapper">
      <div class="content-wrapper__inner">
        <article class="post-container post-container--single">
  <header class="post-header">
    <div class="post-meta">
      <p class="post-meta__body">
        <i class="medium-icon iconify-inline" data-icon="bi:clock-history"></i>
        <span id="reading-time">
          
          3 mins read
        </span>
      </p>
      <time datetime="2019-07-24 00:00" class="post-meta__body date">Published on arXiv on: 24 Jul 2019</time>
      
      <p class="post-meta__tags">Published by: <a href="/labs/#Princeton University">Princeton University</a> & <a href="/labs/#Allen Institute AI">Allen Institute AI</a> & <a href="/labs/#FAIR">FAIR</a></p>
      
    </div>
  </header>

  <section class="post">
    <h1 id=SpanBERT> SpanBERT</h1>
    <p>SpanBERT is a model created by Facebook AI and Allen Institute in
January 2019 and published in this paper “<a href="https://arxiv.org/pdf/1907.10529.pdf">SpanBERT: Improving
Pre-training by Representing and Predicting
Spans</a>”. SpanBERT is just an
extension to BERT where it better represents and predict continuous
random spans of text, rather than random tokens. This is crucial since
many NLP tasks involve spans of text rather than single tokens. SpanBERT
is different from BERT in both the masking scheme and the training
objectives:</p>

<ul>
  <li>
    <p><u><strong>Span Masking:</strong></u><br />
SpanBERT masks random contiguous spans, rather than random
individual tokens which forces the model to predict entire spans
solely using the context in which they appear.</p>
  </li>
  <li>
    <p><u><strong>SBO:</strong></u><br />
SpanBERT uses a novel span-boundary objective (SBO) so the
model learns to predict the entire masked span from the observed
tokens at its boundary which encourages the model to store this
span-level information at the boundary tokens, which can be easily
accessed during the fine-tuning stage.</p>
  </li>
  <li>
    <p><u><strong>No NSP:</strong></u><br />
SpanBERT doesn’t use the NSP objective unlike BERT.</p>
  </li>
</ul>

<div align="center">
    <img src="media/SpanBERT/image1.png" width="750" />
</div>

<h2 id="span-masking">Span Masking</h2>

<p>Given a sequence of tokens X, they selected a subset of tokens by
iteratively sampling spans of text until the masking budget (e.g. 15% of
X) has been spent. And they following the following steps when masking a
subset of tokens:</p>

<ul>
  <li>They randomly sample a span length (number of words) from a
geometric distribution
$\ell \sim Geo(p) = p.\left( 1 - p \right)^{n - 1}$ where
$p = 0.2$ and $\ell_{\max} = 10$ which is skewed towards shorter
spans as shown in the following figure. :</li>
</ul>

<div align="center">
    <img src="media/SpanBERT/image2.png" width="450" />
</div>

<ul>
  <li>
    <p>Then, they randomly select the starting point for the span to be
masked from a uniform distribution. They always sample a sequence
of complete words (instead of subword tokens) and the starting
point must be the beginning of one word.</p>
  </li>
  <li>
    <p>As in BERT, they also masked 15% of the tokens in total: replacing
80% of the masked tokens with [MASK], 10% with random tokens and
10% with the original tokens.</p>
  </li>
</ul>

<h2 id="sbo">SBO</h2>

<p>Span selection models typically create a fixed-length representation of
a span using its boundary tokens (start and end). To support such
models, we would ideally like the representations for the end of the
span to summarize as much of the internal span content as possible. We
do so by introducing a <u><strong>S</strong></u>pan <u><strong>B</strong></u>oundary
<u><strong>O</strong></u>bjective (SBO) that involves predicting each token of a
masked span using only the representations of the observed tokens at the
boundaries.</p>

<p>Formally, they calculated the SBO loss function by following these
steps:</p>

<ul>
  <li>
    <p>Given an input sequence of $X = x_{1},\ …,\ x_{n}$ and a masked
span of tokens $\left( x_{s},…,\ x_{e} \right) \in Y\ $, where
$\left( s,\ e \right)$ indicates its start and end positions
respectively.</p>
  </li>
  <li>
    <p>They represented each token $x_{i}$ in the span using the output
encodings of the external boundary tokens $x_{s - 1}$ and
$x_{e + 1}$, as well as the position embedding of the target token
$p_{i - s + 1}$:</p>
  </li>
</ul>

\[h_{0} = \left\lbrack x_{s - 1};x_{e + 1};p_{i - s + 1} \right\rbrack\]

<ul>
  <li>Then, they implemented the representation function as a 2-layer
feed-forward network with GeLU activations and layer normalization</li>
</ul>

\[h_{1} = \text{LayerNorm}\left( \text{GeLU}\left( W_{1}.h_{0} \right) \right)\]

\[y_{i} = \text{LayerNorm}\left( \text{GeLU}\left( W_{2}.h_{1} \right) \right)\]

<ul>
  <li>Finally, they used the vector representation $y_{i}$ to predict the
token $x_{i}$ and compute the cross-entropy loss exactly like the
MLM objective.</li>
</ul>

\[\mathcal{L}_{\text{SBO}}\left( x_{i} \right) = - log\ P\left( x_{i}\  \middle| \ y_{i} \right)\]

<p>For example, given the following sequence “Super Bowl 50 was an American
football game to determine the champion” where the span “an American
football game” is masked. The span boundary objective (SBO) uses the
output representations of the boundary tokens, x4 and x9 (in blue), to
predict each token in the masked span.</p>

<div align="center">
    <img src="media/SpanBERT/image3.png" width="750" />
</div>

<p>The equation shows the MLM and SBO loss terms for predicting the token,
football (in pink), which as marked by the position embedding $p_{3}$,
is the third token from $x_{4}$.</p>

\[\mathcal{L}\left( \text{football} \right) = \mathcal{L}_{\text{MLM}}\left( \text{football} \right) + \mathcal{L}_{\text{SBO}}\left( \text{football} \right) = - log\ P\left( \text{football} \middle| \ x_{7} \right) - log\ P\left( \text{football} \middle| \ x_{4},x_{9},p_{3} \right)\]

  </section>
</article>

  
  <br><br><br><br>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/language-modeling/SpanBERT';
      this.page.identifier = '/language-modeling/SpanBERT';
    };

    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://Phuc Phan.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>
    Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  <!-- <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a> -->




      </div>
      
<footer class="footer">
  <!-- <span class="footer__copyright">&copy; 2023 Phanxuan Phuc. All rights reserved.</span> -->
  
  <!-- Adding Iconify -->
  <script src="https://code.iconify.design/2/2.0.3/iconify.min.js"></script>
  
  <!-- Adding MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      "tex2jax": {
        inlineMath: [['$','$']],
        processEscapes: true
      },
      "HTML-CSS": { linebreaks: { automatic: true } },
      "SVG": { linebreaks: { automatic: true } },
    });
  </script>
  
  <script type="text/javascript" async
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  
  
  <!-- Adding main.js -->
  <script type="text/javascript" src="/js/main.js?1680763441293376118"></script>
  
  <!-- Adding Google Analytics -->
  
</footer>
    </div>
  </body>
</html>