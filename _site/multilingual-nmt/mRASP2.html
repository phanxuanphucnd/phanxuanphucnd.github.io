<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  

  
  

  
  
  
  
  

  <title>mRASP2</title>
  <meta name="title" content="mRASP2">
  <meta name="description" content="mRASP2 stands for “multilingual Random Aligned
Substitution Pre-training”. It’s mRASP2 because it’s
an extension to the
mRASP model
proposed by the same lab (ByteDance AI Lab) a year earlier. mRASP2
framework was proposed in 2021 and published in this paper: Contrastive
Learning for Many-to-many Multilingual Neural Machine
Translation. The official code
for this paper can be found in this GitHub repository:
mRASP2.

">
  <meta name="author" content="Phanxuan Phuc">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- Google / Search Engine Tags -->
  <meta itemprop="name" content="mRASP2">
  <meta itemprop="description" content="mRASP2 stands for “multilingual Random Aligned
Substitution Pre-training”. It’s mRASP2 because it’s
an extension to the
mRASP model
proposed by the same lab (ByteDance AI Lab) a year earlier. mRASP2
framework was proposed in 2021 and published in this paper: Contrastive
Learning for Many-to-many Multilingual Neural Machine
Translation. The official code
for this paper can be found in this GitHub repository:
mRASP2.

">
  <meta itemprop="image" content="/multilingual-nmt/media/mRASP2/image1.png">

  <!-- OpenGraph Meta Tags -->
  <meta property="og:url" content="http://localhost:4000">
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Phuc Phan's Blog"/>
  <meta property="og:title" content="mRASP2">
  <meta property="og:description" content="mRASP2 stands for “multilingual Random Aligned
Substitution Pre-training”. It’s mRASP2 because it’s
an extension to the
mRASP model
proposed by the same lab (ByteDance AI Lab) a year earlier. mRASP2
framework was proposed in 2021 and published in this paper: Contrastive
Learning for Many-to-many Multilingual Neural Machine
Translation. The official code
for this paper can be found in this GitHub repository:
mRASP2.

">
  <meta property="og:image" content="/multilingual-nmt/media/mRASP2/image1.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="mRASP2">
  <meta name="twitter:description" content="mRASP2 stands for “multilingual Random Aligned
Substitution Pre-training”. It’s mRASP2 because it’s
an extension to the
mRASP model
proposed by the same lab (ByteDance AI Lab) a year earlier. mRASP2
framework was proposed in 2021 and published in this paper: Contrastive
Learning for Many-to-many Multilingual Neural Machine
Translation. The official code
for this paper can be found in this GitHub repository:
mRASP2.

">
  
  <meta name="twitter:image" content="/multilingual-nmt/media/mRASP2/image1.png">

  <link rel="apple-touch-icon" sizes="57x57" href="/images/favicons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/favicons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/favicons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/images/favicons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/favicons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/images/favicons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-194x194.png" sizes="194x194">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-512x512.png" sizes="512x512">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="shortcut icon" href="/images/favicons/favicon.ico">
  <meta name="msapplication-TileColor" content="#ffc40d">
  <meta name="msapplication-TileImage" content="/images/favicons/mstile-144x144.png">
  <meta name="msapplication-square70x70logo" content="/images/favicons/mstile-70x70.png" />
  <meta name="msapplication-square150x150logo" content="/images/favicons/mstile-150x150.png" />
  <meta name="msapplication-wide310x150logo" content="/images/favicons/mstile-310x150.png" />
  <meta name="msapplication-square310x310logo" content="/images/favicons/mstile-310x310.png" />
  <meta name="theme-color" content="#ffffff">
  
  <link rel="stylesheet" href="/css/main.css?1680763441293376118">
  <link rel="canonical" href="http://localhost:4000/multilingual-nmt/mRASP2">
  <link rel="alternate" type="application/rss+xml" title="Phuc Phan's Blog" href="/feed.xml">
  <script type="text/javascript" src="/js/jquery.v3.3.1.min.js"></script>
  <!-- <script type="text/javascript" src="/js/simple-jekyll-search.min.js"></script> -->
  <script type="text/javascript" src="/js/simple-blog-search.min.js"></script>
</head>

  <body>
    <span class="mobile btn-mobile-menu">
  <i class="extra-big-icon iconify-inline icon-list btn-mobile-menu__icon" data-icon="gg:menu-round"></i>
  <i class="extra-big-icon iconify-inline icon-x-circle btn-mobile-close__icon hidden" data-icon="ion:close-circle-outline"></i>
</span>

<header class="panel-cover "
  style="background-image: url(/images/forest.jpg)">
  <div class="panel-main panel-cover--overlay">

    <div class="panel-main__inner panel-inverted">
      <div class="panel-main__content">
        <img src="/images/avatar.jpg" class="user-image"
        onmouseover="this.src='/images/avatar-light.jpg';"
        onmouseout="this.src='/images/avatar.jpg';">
        <h1 class="panel-cover__title panel-title">
          <a href="/">Phanxuan Phuc</a>
        </h1>
        </a>
        <h6 class="panel-cover__title panel-subtitle">fakerphan
          <i class="medium-icon iconify-inline" data-icon="foundation:male-symbol"></i>
        </h6>
        <nav class="cover-navigation navigation--social">
    <ul class="navigation">

      
      <!-- Email -->
      <li class="navigation__item">
        <a href="mailto:phanxuanphucnd@gmail.com" target="_blank" title="Email">
          <i class="big-icon iconify-inline" data-icon="fluent:mail-copy-24-filled"></i>
        </a>
      </li>
      

      
      <!-- LinkedIn -->
      <li class="navigation__item">
        <a href="https://www.linkedin.com/in/phanxuanphucnd" target="_blank" title="LinkedIn">
          <i class="big-icon iconify-inline" data-icon="akar-icons:linkedin-fill"></i>
        </a>
      </li>
      

      
      <!-- GitHub -->
      <li class="navigation__item">
        <a href="https://www.github.com/phanxuanphucnd" target="_blank" title="GitHub">
          <i class="big-icon iconify-inline" data-icon="akar-icons:github-fill"></i>
        </a>
      </li>
      

      <li class="navigation__item">
        <a href="https://scholar.google.com/citations?user=ipcDPCQAAAAJ&hl=vi" title="Google Scholar" target="_blank">
          <i class="big-icon iconify-inline" data-icon="mdi:google"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>

      <li class="navigation__item">
        <a href="https://www.facebook.com/phanxuanphucnd" title="Facebook" target="_blank">
          <i class="big-icon iconify-inline" data-icon="ic:outline-facebook"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>
    </ul>
  </nav>
        
        <form class="search-container" onsubmit="return searchTheArchives()" >
          <input type="search" id="search-input" placeholder="Search.." autocomplete="off" style="padding-right: 40px;">
        </form>

        <hr class="panel-cover__divider panel-cover__divider--secondary">
        
        <div class="navigation-wrapper">
          <p class="panel-cover__description">I’m a AI Engineer in Vin Bigdata. And I summarize research papers in these topics:</p>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              
              
              <li class="navigation__item">
                <a href="/cross-lingual-lm" class="blog-button" id="cross-lingual-lm"
                onclick="activateButton(this.id)">Cross-lingual Langluage Model</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/language-modeling" class="blog-button" id="language-modeling"
                onclick="activateButton(this.id)">Language Modeling</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/machine-translation" class="blog-button" id="machine-translation"
                onclick="activateButton(this.id)">Machine Translation</a>
              </li>
              
              
              
              
              
              <li class="navigation__item">
                <a href="/multilingual-nmt" class="blog-button" id="multilingual-nmt"
                onclick="activateButton(this.id)">Multilingual NMT</a>
              </li>
              
              
              
              
              
              
            </ul>
          </nav>
        </div>
        
        <hr class="panel-cover__divider">
      </div>

    </div>

    <!-- <div class="panel-cover--overlay"></div> -->
  </div>
</header>

    <div class="content-wrapper">
      <div class="content-wrapper__inner">
        <article class="post-container post-container--single">
  <header class="post-header">
    <div class="post-meta">
      <p class="post-meta__body">
        <i class="medium-icon iconify-inline" data-icon="bi:clock-history"></i>
        <span id="reading-time">
          
          6 mins read
        </span>
      </p>
      <time datetime="2021-05-20 00:00" class="post-meta__body date">Published on arXiv on: 20 May 2021</time>
      
      <p class="post-meta__tags">Published by: <a href="/labs/#ByteDance AI Lab">ByteDance AI Lab</a></p>
      
    </div>
  </header>

  <section class="post">
    <h1 id=mRASP2> mRASP2</h1>
    <p>mRASP2 stands for “<strong>m</strong>ultilingual <strong>R</strong>andom <strong>A</strong>ligned
<strong>S</strong>ubstitution <strong>P</strong>re-training”. It’s mRASP<u><strong>2</strong></u> because it’s
an extension to the
<a href="https://phanxuanphucnd.github.io/multilingual-nmt/mRASP">mRASP</a> model
proposed by the same lab (ByteDance AI Lab) a year earlier. mRASP2
framework was proposed in 2021 and published in this paper: <a href="https://arxiv.org/pdf/2105.09501.pdf">Contrastive
Learning for Many-to-many Multilingual Neural Machine
Translation</a>. The official code
for this paper can be found in this GitHub repository:
<a href="https://github.com/PANXiao1994/mRASP2">mRASP2</a>.</p>

<p>mRASP2, as shown in the following figure, is a framework for training
many-to-many multilingual neural machine translation models using both
parallel corpora and monolingual corpora. This framework is empowered by
two techniques:</p>

<ul>
  <li>
    <p><strong>mCOLT:</strong> a contrastive learning scheme for the encoder to close
the gap among representations of similar sentences across different
languages.</p>
  </li>
  <li>
    <p><strong>Aligned Augmentation (AA):</strong> Data augmentation on both parallel
and monolingual data to create pseudo-pairs to improve multilingual
translation quality.</p>
  </li>
</ul>

<div align="center">
    <img src="media/mRASP2/image1.png" width="750" />
</div>

<p>The base architecture of mRASP2 is the state-of-the-art
<a href="https://phanxuanphucnd.github.io/machine-translation/Transformer">Transformer</a>.
A little different from
<a href="https://phanxuanphucnd.github.io/multilingual-nmt/mRASP">mRASP</a>, they chose a larger
setting with a 12-layer encoder and a 12-layer decoder to increase the model
capacity. The model dimension is $1024$ on $16$ heads. To ease the training of
the deep model, they applied Layer Normalization for word embedding and
pre-norm residual connection for both encoder and decoder.</p>

<p>More formally, $D$ denotes all parallel datasets involved in training where
$D_{i,j}$ denotes a parallel dataset of $\left( L_{i},\ L_{j} \right)$ language
pair. To distinguish different languages, they added an additional language
identification token preceding each sentence, for both source side and target
side.</p>

<h2 id="mcolt">mCOLT</h2>

<p>mCOLT stands for “<strong>m</strong>ultilingual <strong>Co</strong>ntrastive <strong>L</strong>earning for
<strong>T</strong>ranslation” which is a contrastive loss function for the encoder.
Its key idea is to minimize the representation gap of similar sentences
of different languages and maximize that of irrelevant sentences. More
formally, given a bilingual translation pairs
$\left( x^{i},\ x^{j} \right) \in D$ where
$\left( x^{i},\ x^{j} \right)$ is a positive example, and
$\left( x^{i},\ y^{j} \right)$ is a negative example as $y^{j}$ is
randomly sampled from the same language $L_{j}$. The objective of
contrastive learning is to minimize the following loss:</p>

\[\mathcal{L}_{\text{ctr}} = \sum_{x^{i},x^{j} \in D}^{}{- \log\left( \frac{\frac{e^{\text{sim}^{+}\left( \mathcal{R}\left( x^{i} \right),\ \mathcal{R}\left( x^{j} \right) \right)}}{t}}{\sum_{y^{j}}^{}\frac{e^{\text{sim}^{-}\left( \mathcal{R}\left( x^{i} \right),\ \mathcal{R}\left( y^{j} \right) \right)}}{t}} \right)}\]

<p>Where:</p>

<ul>
  <li>
    <p>$sim()$ calculates the cosine similarity of different sentences.
$sim +$ and $sim -$ denote positive and negative similarity
respectively. To simplify implementation, the negative samples are
sampled from the same training batch.</p>
  </li>
  <li>
    <p>$\mathcal{R}\left( x \right)$ denotes the encoded output of an
arbitrary sentence $x$.</p>
  </li>
  <li>
    <p>$t$ is the temperature. Higher temperature increases the difficulty
to distinguish positive sample from negative ones. In the paper,
temperature was set to $0.1$.</p>
  </li>
</ul>

<p>Now, the training loss $\mathcal{L}$ used for training mRASP2 is a combination
of two loss functions; the contrastive loss <span>$\mathcal{L}_{\text{ctr}}$</span>
defined above and the cross entropy <span>$\mathcal{L}_{\text{ce}}$</span>:</p>

\[\mathcal{L} = \mathcal{L}_{\text{ce}} + \lambda\left| s \right|\mathcal{L}_{\text{ctr}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \mathcal{L}_{\text{ce}} = \sum_{x^{i},x^{j} \in D}^{}{- \log\left( P_{\theta}\left( x^{i} \middle| x^{j} \right) \right)}\]

<p>Where</p>

<ul>
  <li>
    <p>$\lambda$ is the coefficient to balance the two training losses. In
the paper, it was set to $1.0$.</p>
  </li>
  <li>
    <p>$\left| s \right|$ is the average sequence length since
<span>$\mathcal{L}_{\text{ctr}}$</span> is calculated on the sentence-level
and <span>$\mathcal{L}_{\text{ce}}$</span> is calculated on the token-level.</p>
  </li>
  <li>
    <p>$x^{i}$ and $x^{j}$ represent sentences in language $L_{i}$ and
$L_{j}$ respectively.</p>
  </li>
  <li>
    <p>$\theta$ is the parameter of multilingual Transformer model.</p>
  </li>
</ul>

<h2 id="aligned-augmentation">Aligned Augmentation</h2>

<p>Aligned Augmentation (AA) is a data augmentation technique that can be
applied on both parallel and monolingual data in order to improve
multilingual translation quality. Aligned Augmentation is considered an
extension of RAS (Random Aligned Substitution) which was proposed in
<a href="https://phanxuanphucnd.github.io/multilingual-nmt/mRASP">mRASP</a> paper.</p>

<p>For a bilingual sentence pair $\left( x^{i},\ x^{j} \right)$ in two
languages $L_{i}$ and $L_{j}$, Aligned Augmentation creates a perturbed
sentence $C\left( x^{i} \right)$ by replacing aligned words from a
<a href="https://phanxuanphucnd.github.io/machine-translation/MUSE">MUSE</a> synonym
dictionary with a probability of $90\%$ and keep them unchanged
otherwise; forming a pseudo-parallel training example
$\left( C\left( x^{i} \right),\ x^{j} \right)$:</p>

<div align="center">
    <img src="media/mRASP2/image2.png" width="750" />
</div>

<p>For a monolingual sentence $x^{i}$ of language $L_{i}$, Aligned
Augmentation creates a perturbed sentence $C\left( x^{i} \right)$ the
same way as the bilingual sentence; forming a pseudo self-parallel
example $\left( C\left( x^{i} \right),\ x^{i} \right)$:</p>

<div align="center">
    <img src="media/mRASP2/image3.png" width="750" />
</div>

<p>Now, both a pseudo-parallel training example
$\left( C\left( x^{i} \right),\ x^{j} \right)$ and a pseudo
self-parallel example $\left( C\left( x^{i} \right),\ x^{i} \right)$
will be used to increase the training data and therefore boosting the
multilingual translation quality.</p>

<h2 id="experiments">Experiments</h2>

<p>In their experiments, they used the
<a href="https://phanxuanphucnd.github.io/machine-translation/Transformer">Transformer</a>
model with 12 encoder layers and 12 decoder layers. The embedding size
and FFN dimension were set to $1024$ on $16$ heads. For multilingual
vocabulary, They followed the shared BPE vocabulary of $64,808$ tokens
plus $59$ language tokens such as
$\left\langle \text{EN\ id} \right\rangle$,
$\left\langle \text{FR\ id} \right\rangle$...etc.</p>

<p>They also used a dropout rate of $0.1$, as well as a learning rate of
$3e^{- 4}$ with polynomial decay scheduling and a warm-up step of $10k$.
For optimization, they use Adam optimizer with $\epsilon = 1e^{- 6}$ and
$\beta_{2} = 0.98$. To stabilize training, they set the threshold of
gradient norm to be $5.0$ and clip all gradients with a larger norm.</p>

<p>For bilingual data, they used the Parallel Corpus (PC32) proposed in the
<a href="https://phanxuanphucnd.github.io/multilingual-nmt/mRASP">mRASP</a> paper. PC32
contains 97.6 million parallel sentences of 32 English-centric language
pairs. The following figure shows the languages found in the corpus
along with the number of sentences available for each language:</p>

<div align="center">
    <img src="media/mRASP2/image4.png" width="750" />
</div>

<p>For monolingual data, they created Monolingual Corpus (MC24) of 1.01
billion sentences of 24 languages. MC24 is a subset of the <a href="http://data.statmt.org/news-crawl">Newscrawl
dataset</a> by using only those
languages in PC32, plus three additional languages (Nl, Pl, Pt)
highlighted in red in the following figure:</p>

<div align="center">
    <img src="media/mRASP2/image5.png" width="750" />
</div>

<p>In order to balance the volume across different languages, they applied
temperature sampling of $T = 5$. For a given language pair $l$ with
$D_{l}$ number of parallel sentences, the probability of the sample
being from language $l$ is:</p>

\[p_{l} = \left( \frac{D_{l}}{\sum_{k}^{}D_{k}} \right)^{\frac{1}{T}}\]

<h2 id="results">Results</h2>

<p>The following table shows the BLEU score of different models (bilingual,
pre-trained then fine-tuned, and multilingual) on the evaluation sets of
WMT benchmark. As shown in the following table, mRASP2 clearly improves
multilingual baselines by a large margin in 10 translation directions.</p>

<div align="center">
    <img src="media/mRASP2/image6.png" width="750" />
</div>

<blockquote>
  <p><strong>Note:</strong><br />
m-Transformer is a many-to-many 12 layers standard transformer model
trained on PC32 dataset and used as a baseline. As we can see from the
past table, this model achieves very competitive results and they
explained that that was due to these reasons:</p>

  <ul>
    <li>
      <p>They used a batch size of 3 million tokens. The batch size plays a
  crucial role in the success of training multilingual NMTs.</p>
    </li>
    <li>
      <p>They used gradient norm to stable the training. Without it, the
  large scale training will collapse sometimes.</p>
    </li>
  </ul>
</blockquote>

<p>The following table shows the BLEU score of unsupervised translation on IWSLT,
WMT, and OPUS-100 evaluations sets. These three models were trained on only
monolingual data and mRASP2 outperforms them by a huge margin on all
language-pairs:</p>

<div align="center">
    <img src="media/mRASP2/image7.png" width="750" />
</div>

<p>The following table shows the BLEU score of zero-shot translation on OPUS-100
evaluations sets. As we can see, mRASP2 achieves consistent BLEU gains in
zero-shot directions on different evaluation sets:</p>

<div align="center">
    <img src="media/mRASP2/image8.png" width="750" />
</div>

<p>To understand what contributes to the performance gain, they conducted
analytical experiments and reported the results in the following table:</p>

<div align="center">
    <img src="media/mRASP2/image9.png" width="750" />
</div>

<p>And they found out the following:</p>

<ul>
  <li>
    <p>③ performs comparably with ① in supervised and unsupervised scenarios,
whereas achieves a substantial BLEU improvement for zero-shot translation. <u><strong>This indicates that by introducing contrastive loss, we can
improve zero-shot translation quality without harming other
directions.</strong></u></p>
  </li>
  <li>
    <p>① and ② perform poorly for zero-shot directions. <u><strong>This means
contrastive loss is crucial for the performance in zero-shot
directions.</strong></u></p>
  </li>
  <li>
    <p>mRASP2 further improves BLEU in ③, ④, and ⑤ especially in unsupervised
directions. Therefore it is safe to say that <u><strong>mRASP2 learns a
better representation space by using monolingual data.</strong></u></p>
  </li>
</ul>

  </section>
</article>

  
  <br><br><br><br>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/multilingual-nmt/mRASP2';
      this.page.identifier = '/multilingual-nmt/mRASP2';
    };

    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://Phuc Phan.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>
    Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  <!-- <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a> -->




      </div>
      
<footer class="footer">
  <!-- <span class="footer__copyright">&copy; 2023 Phanxuan Phuc. All rights reserved.</span> -->
  
  <!-- Adding Iconify -->
  <script src="https://code.iconify.design/2/2.0.3/iconify.min.js"></script>
  
  <!-- Adding MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      "tex2jax": {
        inlineMath: [['$','$']],
        processEscapes: true
      },
      "HTML-CSS": { linebreaks: { automatic: true } },
      "SVG": { linebreaks: { automatic: true } },
    });
  </script>
  
  <script type="text/javascript" async
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  
  
  <!-- Adding main.js -->
  <script type="text/javascript" src="/js/main.js?1680763441293376118"></script>
  
  <!-- Adding Google Analytics -->
  
</footer>
    </div>
  </body>
</html>