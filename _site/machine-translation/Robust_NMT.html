<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  

  
  

  
  
  
  
  

  <title>Robust NMT</title>
  <meta name="title" content="Robust NMT">
  <meta name="description" content="Neural machine translation (NMT) often suffers from the vulnerability to
noisy perturbation in the input. Google AI has proposed an approach to
improving the robustness of NMT models called AdvGen published in 2019
in their paper: Robust Neural Machine Translation with Doubly
Adversarial Inputs. AdvGen
consists of two parts:

">
  <meta name="author" content="Phanxuan Phuc">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- Google / Search Engine Tags -->
  <meta itemprop="name" content="Robust NMT">
  <meta itemprop="description" content="Neural machine translation (NMT) often suffers from the vulnerability to
noisy perturbation in the input. Google AI has proposed an approach to
improving the robustness of NMT models called AdvGen published in 2019
in their paper: Robust Neural Machine Translation with Doubly
Adversarial Inputs. AdvGen
consists of two parts:

">
  <meta itemprop="image" content="/machine-translation/media/Robust_NMT/image0.png">

  <!-- OpenGraph Meta Tags -->
  <meta property="og:url" content="http://localhost:4000">
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Phuc Phan's Blog"/>
  <meta property="og:title" content="Robust NMT">
  <meta property="og:description" content="Neural machine translation (NMT) often suffers from the vulnerability to
noisy perturbation in the input. Google AI has proposed an approach to
improving the robustness of NMT models called AdvGen published in 2019
in their paper: Robust Neural Machine Translation with Doubly
Adversarial Inputs. AdvGen
consists of two parts:

">
  <meta property="og:image" content="/machine-translation/media/Robust_NMT/image0.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Robust NMT">
  <meta name="twitter:description" content="Neural machine translation (NMT) often suffers from the vulnerability to
noisy perturbation in the input. Google AI has proposed an approach to
improving the robustness of NMT models called AdvGen published in 2019
in their paper: Robust Neural Machine Translation with Doubly
Adversarial Inputs. AdvGen
consists of two parts:

">
  
  <meta name="twitter:image" content="/machine-translation/media/Robust_NMT/image0.png">

  <link rel="apple-touch-icon" sizes="57x57" href="/images/favicons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/favicons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/favicons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/images/favicons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/favicons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/images/favicons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-194x194.png" sizes="194x194">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-512x512.png" sizes="512x512">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="shortcut icon" href="/images/favicons/favicon.ico">
  <meta name="msapplication-TileColor" content="#ffc40d">
  <meta name="msapplication-TileImage" content="/images/favicons/mstile-144x144.png">
  <meta name="msapplication-square70x70logo" content="/images/favicons/mstile-70x70.png" />
  <meta name="msapplication-square150x150logo" content="/images/favicons/mstile-150x150.png" />
  <meta name="msapplication-wide310x150logo" content="/images/favicons/mstile-310x150.png" />
  <meta name="msapplication-square310x310logo" content="/images/favicons/mstile-310x310.png" />
  <meta name="theme-color" content="#ffffff">
  
  <link rel="stylesheet" href="/css/main.css?1680763441293376118">
  <link rel="canonical" href="http://localhost:4000/machine-translation/Robust_NMT">
  <link rel="alternate" type="application/rss+xml" title="Phuc Phan's Blog" href="/feed.xml">
  <script type="text/javascript" src="/js/jquery.v3.3.1.min.js"></script>
  <!-- <script type="text/javascript" src="/js/simple-jekyll-search.min.js"></script> -->
  <script type="text/javascript" src="/js/simple-blog-search.min.js"></script>
</head>

  <body>
    <span class="mobile btn-mobile-menu">
  <i class="extra-big-icon iconify-inline icon-list btn-mobile-menu__icon" data-icon="gg:menu-round"></i>
  <i class="extra-big-icon iconify-inline icon-x-circle btn-mobile-close__icon hidden" data-icon="ion:close-circle-outline"></i>
</span>

<header class="panel-cover "
  style="background-image: url(/images/forest.jpg)">
  <div class="panel-main panel-cover--overlay">

    <div class="panel-main__inner panel-inverted">
      <div class="panel-main__content">
        <img src="/images/avatar.jpg" class="user-image"
        onmouseover="this.src='/images/avatar-light.jpg';"
        onmouseout="this.src='/images/avatar.jpg';">
        <h1 class="panel-cover__title panel-title">
          <a href="/">Phanxuan Phuc</a>
        </h1>
        </a>
        <h6 class="panel-cover__title panel-subtitle">fakerphan
          <i class="medium-icon iconify-inline" data-icon="foundation:male-symbol"></i>
        </h6>
        <nav class="cover-navigation navigation--social">
    <ul class="navigation">

      
      <!-- Email -->
      <li class="navigation__item">
        <a href="mailto:phanxuanphucnd@gmail.com" target="_blank" title="Email">
          <i class="big-icon iconify-inline" data-icon="fluent:mail-copy-24-filled"></i>
        </a>
      </li>
      

      
      <!-- LinkedIn -->
      <li class="navigation__item">
        <a href="https://www.linkedin.com/in/phanxuanphucnd" target="_blank" title="LinkedIn">
          <i class="big-icon iconify-inline" data-icon="akar-icons:linkedin-fill"></i>
        </a>
      </li>
      

      
      <!-- GitHub -->
      <li class="navigation__item">
        <a href="https://www.github.com/phanxuanphucnd" target="_blank" title="GitHub">
          <i class="big-icon iconify-inline" data-icon="akar-icons:github-fill"></i>
        </a>
      </li>
      

      <li class="navigation__item">
        <a href="https://scholar.google.com/citations?user=ipcDPCQAAAAJ&hl=vi" title="Google Scholar" target="_blank">
          <i class="big-icon iconify-inline" data-icon="mdi:google"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>

      <li class="navigation__item">
        <a href="https://www.facebook.com/phanxuanphucnd" title="Facebook" target="_blank">
          <i class="big-icon iconify-inline" data-icon="ic:outline-facebook"></i>
          <!-- <span class="label">RSS</span> -->
        </a>
      </li>
    </ul>
  </nav>
        
        <form class="search-container" onsubmit="return searchTheArchives()" >
          <input type="search" id="search-input" placeholder="Search.." autocomplete="off" style="padding-right: 40px;">
        </form>

        <hr class="panel-cover__divider panel-cover__divider--secondary">
        
        <div class="navigation-wrapper">
          <p class="panel-cover__description">Iâ€™m a AI Engineer in Vin Bigdata. And I summarize research papers in these topics:</p>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              
              
              <li class="navigation__item">
                <a href="/cross-lingual-lm" class="blog-button" id="cross-lingual-lm"
                onclick="activateButton(this.id)">Cross-lingual Langluage Model</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/language-modeling" class="blog-button" id="language-modeling"
                onclick="activateButton(this.id)">Language Modeling</a>
              </li>
              
              
              
              <li class="navigation__item">
                <a href="/machine-translation" class="blog-button" id="machine-translation"
                onclick="activateButton(this.id)">Machine Translation</a>
              </li>
              
              
              
              
              
              <li class="navigation__item">
                <a href="/multilingual-nmt" class="blog-button" id="multilingual-nmt"
                onclick="activateButton(this.id)">Multilingual NMT</a>
              </li>
              
              
              
              
              
              
            </ul>
          </nav>
        </div>
        
        <hr class="panel-cover__divider">
      </div>

    </div>

    <!-- <div class="panel-cover--overlay"></div> -->
  </div>
</header>

    <div class="content-wrapper">
      <div class="content-wrapper__inner">
        <article class="post-container post-container--single">
  <header class="post-header">
    <div class="post-meta">
      <p class="post-meta__body">
        <i class="medium-icon iconify-inline" data-icon="bi:clock-history"></i>
        <span id="reading-time">
          
          4 mins read
        </span>
      </p>
      <time datetime="2019-06-06 00:00" class="post-meta__body date">Published on arXiv on: 6 Jun 2019</time>
      
      <p class="post-meta__tags">Published by: <a href="/labs/#Google AI">Google AI</a></p>
      
    </div>
  </header>

  <section class="post">
    <h1 id=Robust NMT> Robust NMT</h1>
    <p>Neural machine translation (NMT) often suffers from the vulnerability to
noisy perturbation in the input. Google AI has proposed an approach to
improving the robustness of NMT models called AdvGen published in 2019
in their paper: <a href="https://arxiv.org/pdf/1906.02443.pdf">Robust Neural Machine Translation with Doubly
Adversarial Inputs</a>. AdvGen
consists of two parts:</p>

<ul>
  <li>
    <p>Attack the translation model with adversarial source examples.</p>
  </li>
  <li>
    <p>Defend the translation model with adversarial target inputs to
improve its robustness against the adversarial source inputs.</p>

    <p>This approach achieves significant improvements over the previous
state-of-the-art Transformer model on two common translation
benchmarks: Chinese-English and English-German which substantiates
that the proposed model improves the generalization performance over
the clean benchmark datasets.</p>
  </li>
</ul>

<h2 id="advgen">AdvGen</h2>

<p>AdvGen is a gradient-based approach to construct adversarial examples
and use these examples to both attack as well as defend the NMT model.
The intuition behind it is that an ideal model would generate similar
translation results for similar input sentences despite any small
difference caused by perturbations.</p>

<h3 id="attack-source-input">Attack Source Input</h3>

<p>Given a parallel sentence pair $(x,\ y)$, For the original input $x$, we
induce a possible adversarial word ${xâ€™}<em>{i}$ for the token $x</em>{i}$ in
x:</p>

\[{x'}_{i} = \underset{x \in \mathcal{V}_{x_{i}}}{\arg\max}\left( \text{sim}\left( e\left( x \right) - e\left( x_{i} \right) \right),\ g_{x_{i}} \right)\]

<p>Where:</p>

<ul>
  <li>
    <p>$e\left( x_{i} \right)$ is the embedding of token $x_{i}$.</p>
  </li>
  <li>
    <p>$g_{x_{i}}$ is a gradient vector with respect to
$e\left( x_{i} \right)$:</p>
  </li>
</ul>

\[g_{x_{i}} = \frac{\partial}{\partial e\left( x_{i} \right)} - logP\left( y \middle| x;\ \theta \right)\]

<ul>
  <li>
    <p>$sim( \cdot ,\  \cdot )$ denotes the similarity function by
calculating the cosine distance between two vectors.</p>
  </li>
  <li>
    <p><span>$\mathcal{V}_{x_{i}}$</span> is a subset of the vocabulary for
the source language that is specific for each token <span>$x_{i}$</span>
is defined as the n most probable words among the top n scores calculated
by $a$ is a bidirectional language model for the source language
<span>$P_{\text{lm}}$</span>:</p>
  </li>
</ul>

\[\mathcal{V}_{x_{i}} = top\_ n\left( Q\left( x_{i},\ x \right) \right);\ \ \ \ Q\left( x_{i},\ x \right) = P_{\text{lm}}\left( x \middle| x_{&lt; i},\ x_{&gt; i};\ \theta_{\text{lm}}^{x} \right)\]

<p>More formally, the AdvGen function can be written as an algorithm like so:</p>

<div align="center">
    <img src="media/Robust_NMT/image1.png" width="550" />
</div>

<h3 id="defense-target-input">Defense Target Input</h3>

<p>After generating an adversarial example $xâ€™$, we treat $(xâ€™,\ y)$ as a
new training data point to improve the modelâ€™s robustness. These
adversarial examples in the source tend to introduce errors which may
accumulate and cause drastic changes to the decoder prediction. To
defend the model from errors in the decoder predictions, AdvGen
generates an adversarial target input.</p>

<p>Formally, let $z$ be the decoder input for the sentence pair $(x,\ y)$.
Using the same AdvGen function, we will generate an adversarial target
input $zâ€™$ from $z$ by:</p>

\[z' = \text{AdvGen}\left( z,\ Q_{\text{trg}},\ D_{\text{trg}},\  - \log P\left( y \middle| x' \right) \right)\]

<p>Note that:</p>

<ul>
  <li>
    <p>For the target, the translation loss in the attack part
$- logP\left( y \middle| x;\ \theta \right)$ is replaced by
$- logP\left( y \middle| xâ€™ \right)$.</p>
  </li>
  <li>
    <p><span>$Q_{\text{trg}}$</span> is the likelihood for selecting the target
word candidate set <span>$\mathcal{V}_{z}$</span>. To compute it, we combine
the NMT model prediction <span>$P_{\text{nmt}}$</span> with a bidirectional
language model <span>$P_{\text{lm}}$</span> for the target language with a
tunable hyper-parameter <span>$\lambda$<span> that balances the importance
between two models as follow:</span></span></p>
  </li>
</ul>

\[Q_{\text{trg}}\left( z_{i},\ z \right) = \lambda P_{\text{lm}}\left( z \middle| z_{&lt; i},\ z_{&gt; i};\ \theta_{\text{lm}}^{y} \right) + \left( 1 - \lambda \right)P_{\text{nmt}}\left( z \middle| z_{&lt; i},\ x';\ \theta_{\text{nmt}} \right)\]

<ul>
  <li>$D_{\text{trg}}$ is a distribution for sampling positions for the
target input. Different from the uniform distribution used in the
source, in the target sentence we want to change those relevant
words influenced by the perturbed words in the source input. To do
so, we use the attention matrix $M$ learned in the NMT model,
obtained at the current mini-batch, to compute the distribution over
$(x,\ y,\ xâ€™)$ by:</li>
</ul>

\[P\left( j \right) = \frac{\sum_{i}^{}M_{\text{ij}}\ \delta\left( x_{i},\ {x'}_{i} \right)}{\sum_{k}^{}{\sum_{i}^{}M_{\text{ik}}\ \delta\left( x_{i},\ {x'}_{i} \right)}},\ \ \ j \in \left\lbrack 1,\ ...,\ \left| y \right| \right\rbrack\]

<p>Where <span>$M_{\text{ij}}$</span> is the attention score between
<span>$x_{i}$</span> and <span>$y_{j}$</span>; and
<span>$\delta\left( x_{i},\ {xâ€™}_{i} \right)$</span> is an indicator function
that yields 1 if <span>$x_{i} \neq {xâ€™}_{i}$</span> and 0 otherwise.</p>

<h2 id="robustness-loss">Robustness Loss</h2>

<div align="center">
    <img src="media/Robust_NMT/image2.png" width="550" />
</div>

<p>This algorithm details the entire procedure to
calculate the robustness loss for a parallel sentence pair $(x,\ y)$.
This algorithm takes at most a 20% time overhead compared to the
standard Transformer model.</p>

<p>Accordingly, we compute the robustness loss on $S$ as:</p>

\[\mathcal{L}_{\text{robust}}\left( \theta_{\text{nmt}} \right) = \frac{1}{\left| S \right|}\sum_{\left( x,y \right) \in S}^{}{- \log P\left( y \middle| x',\ z';\ \theta_{\text{nmt}} \right)}\]

<p>And the final loss will be a combination of four loss functions:</p>

\[\mathcal{L}\left( \theta_{\text{nmt}},\ \theta_{\text{lm}}^{x},\ \theta_{\text{lm}}^{y} \right) = \mathcal{L}_{\text{clean}}\left( \theta_{\text{nmt}} \right) + \mathcal{L}_{\text{lm}}\left( \theta_{\text{lm}}^{x} \right) + \mathcal{L}_{\text{robust}}\left( \theta_{\text{nmt}} \right) + \mathcal{L}_{\text{lm}}\left( \theta_{\text{lm}}^{y} \right)\]

<p>Where:</p>

<ul>
  <li>
    <p><span>$\mathcal{L}_{\text{lm}}\left( \theta_{\text{lm}}^{x} \right)$</span>
and <span>$\mathcal{L}_{\text{lm}}\left( \theta_{\text{lm}}^{y} \right)$</span>
are loss functions for source and target bidirectional language models,
respectively.</p>
  </li>
  <li>
    <p><span>$\mathcal{L}_{\text{clean}}\left( \theta_{\text{nmt}} \right)$</span>
is the loss function for the NMT model.</p>
  </li>
  <li>
    <p><span>$\mathcal{L}_{\text{robust}}\left( \theta_{\text{nmt}} \right)$</span>
is the robustness loss.</p>
  </li>
</ul>

  </section>
</article>

  
  <br><br><br><br>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/machine-translation/Robust_NMT';
      this.page.identifier = '/machine-translation/Robust_NMT';
    };

    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://Phuc Phan.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>
    Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  <!-- <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a> -->




      </div>
      
<footer class="footer">
  <!-- <span class="footer__copyright">&copy; 2023 Phanxuan Phuc. All rights reserved.</span> -->
  
  <!-- Adding Iconify -->
  <script src="https://code.iconify.design/2/2.0.3/iconify.min.js"></script>
  
  <!-- Adding MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      "tex2jax": {
        inlineMath: [['$','$']],
        processEscapes: true
      },
      "HTML-CSS": { linebreaks: { automatic: true } },
      "SVG": { linebreaks: { automatic: true } },
    });
  </script>
  
  <script type="text/javascript" async
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  
  
  <!-- Adding main.js -->
  <script type="text/javascript" src="/js/main.js?1680763441293376118"></script>
  
  <!-- Adding Google Analytics -->
  
</footer>
    </div>
  </body>
</html>